{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/unit8co/AMLD2025/03_finetuning_and_rl/001_finetuning_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FP9iL_yPc0o"
      },
      "source": [
        "## Fine-tuning (& Reinforcement Learning)\n",
        "\n",
        "In this notebook, we'll focus exclusively on working with local models. We'll explore three key aspects:\n",
        "1. Evaluating how a small local model performs on coverage checks without any modifications\n",
        "2. Enhancing the model's performance through Supervised Fine Tuning (SFT)\n",
        "3. Investigating how reinforcement learning can improve the model's reasoning capabilities specifically for claim analysis (in the next notebook).\n",
        "\n",
        "For this workshop, we'll use [Qwen2.5 3B](https://qwenlm.github.io/blog/qwen2.5/), which offers impressive performance despite its compact size. Note: The 3B version is licensed for non-commercial use only.\n",
        "\n",
        "Our fine-tuning process will utilize [unsloth](https://docs.unsloth.ai/), a library that enables efficient LLM fine-tuning with minimal resources through several optimizations:\n",
        "- By default implementation of [QLoRA](https://arxiv.org/abs/2305.14314) for 4-bit model loading\n",
        "- Performance optimization via custom [OpenAI's triton](https://openai.com/index/triton/) CUDA kernels\n",
        "- Enhanced inference speed using [vllm](https://github.com/vllm-project/vllm) (an optimized LLM inference server deployment framework)\n",
        "\n",
        "Lastly, we'll leverage unsloth to implement Grouped Policy Optimization (GRPO) - the same technique used in DeepSeek R1 - to develop a specialized reasoning model for claim analysis in the next notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq6IJ0h0Pc0p"
      },
      "source": [
        "### Qwen 2.5 baseline\n",
        "\n",
        "Before we begin finetuning, we need to establish a baseline with our local model Qwen 2.5 3B."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN1qMyMQPc0p"
      },
      "source": [
        "#### load and prepare the dataset\n",
        "\n",
        "We will load the same dataset used in the previous part of this workshop: 400 synthetic claims related to AXA UK's car insurance policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XD7684oORWKW"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # clone the repo, install dependencies,\n",
        "    !git clone https://github.com/unit8co/AMLD2025.git\n",
        "    !curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "    !/root/.local/bin/uv pip install --system -r AMLD2025/pyproject.toml\n",
        "\n",
        "    # add cloned folder to python path to resolve import\n",
        "    sys.path.insert(0, \"AMLD2025/03_finetuning_and_rl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoGgt2onPc0p",
        "outputId": "97b6e73f-1b78-4c75-c95f-117138ec528b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded dataset with 400 claims.\n"
          ]
        }
      ],
      "source": [
        "# we use pydantic models to help you navigate / type the dataset\n",
        "from models import ClaimsDataset\n",
        "\n",
        "with open(\"AMLD2025/data/claims_dataset_v2_manual.json\", \"r\") as f:\n",
        "    dataset = ClaimsDataset.model_validate_json(f.read())\n",
        "\n",
        "print(f\"loaded dataset with {len(dataset.root)} claims.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LEm_sC0PPc0q",
        "outputId": "d49252d0-a85e-40e1-9335-1bbf29f576b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on class Claim in module models:\n",
            "\n",
            "class Claim(pydantic.main.BaseModel)\n",
            " |  Claim(*, description: str, explanation: str, coverage: bool, sources: list[models.Source], source_rule: models.SourceRuleContainer, limit_unit: str | None = None, limit_amount: float | None = None, limit_targets: list[str]) -> None\n",
            " |  \n",
            " |  Represents an individual insurance claim with all its details and\n",
            " |  associated rules.\n",
            " |  \n",
            " |  Attributes:\n",
            " |      description (str): Detailed description of the claim scenario\n",
            " |      explanation (str): Additional explanation or notes about the claim\n",
            " |      coverage (bool): Whether the claim is covered under the policy\n",
            " |      sources (list[Source]): Relevant policy document excerpts supporting\n",
            " |          the claim\n",
            " |      source_rule (SourceRuleContainer): Collection of rules applicable to\n",
            " |          the claim\n",
            " |      limit_unit (Optional[str]): Currency unit for the claim limit (e.g.,\n",
            " |          \"GBP\")\n",
            " |      limit_amount (Optional[float]): Maximum amount covered for the claim\n",
            " |      limit_targets (list[str]): list of entities to whom the limit applies\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Claim\n",
            " |      pydantic.main.BaseModel\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  __annotations__ = {'coverage': <class 'bool'>, 'description': <class '...\n",
            " |  \n",
            " |  __class_vars__ = set()\n",
            " |  \n",
            " |  __private_attributes__ = {}\n",
            " |  \n",
            " |  __pydantic_complete__ = True\n",
            " |  \n",
            " |  __pydantic_computed_fields__ = {}\n",
            " |  \n",
            " |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'models.Sou...\n",
            " |  \n",
            " |  __pydantic_custom_init__ = False\n",
            " |  \n",
            " |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
            " |  \n",
            " |  __pydantic_fields__ = {'coverage': FieldInfo(annotation=bool, required...\n",
            " |  \n",
            " |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
            " |  \n",
            " |  __pydantic_parent_namespace__ = None\n",
            " |  \n",
            " |  __pydantic_post_init__ = None\n",
            " |  \n",
            " |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
            " |      Model...\n",
            " |  \n",
            " |  __pydantic_validator__ = SchemaValidator(title=\"Claim\", validator=Mode...\n",
            " |  \n",
            " |  __signature__ = <Signature (*, description: str, explanation: st...| N...\n",
            " |  \n",
            " |  model_config = {}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from pydantic.main.BaseModel:\n",
            " |  \n",
            " |  __copy__(self) -> 'Self'\n",
            " |      Returns a shallow copy of the model.\n",
            " |  \n",
            " |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
            " |      Returns a deep copy of the model.\n",
            " |  \n",
            " |  __delattr__(self, item: 'str') -> 'Any'\n",
            " |      Implement delattr(self, name).\n",
            " |  \n",
            " |  __eq__(self, other: 'Any') -> 'bool'\n",
            " |      Return self==value.\n",
            " |  \n",
            " |  __getattr__(self, item: 'str') -> 'Any'\n",
            " |  \n",
            " |  __getstate__(self) -> 'dict[Any, Any]'\n",
            " |      Helper for pickle.\n",
            " |  \n",
            " |  __init__(self, /, **data: 'Any') -> 'None'\n",
            " |      Create a new model by parsing and validating input data from keyword arguments.\n",
            " |      \n",
            " |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
            " |      validated to form a valid model.\n",
            " |      \n",
            " |      `self` is explicitly positional-only to allow `self` as a field name.\n",
            " |  \n",
            " |  __iter__(self) -> 'TupleGenerator'\n",
            " |      So `dict(model)` works.\n",
            " |  \n",
            " |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
            " |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
            " |  \n",
            " |  __replace__(self, **changes: 'Any') -> 'Self'\n",
            " |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
            " |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
            " |  \n",
            " |  __repr__(self) -> 'str'\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __repr_args__(self) -> '_repr.ReprArgs'\n",
            " |  \n",
            " |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
            " |      Name of the instance's class, used in __repr__.\n",
            " |  \n",
            " |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
            " |      Returns the string representation of a recursive object.\n",
            " |  \n",
            " |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
            " |  \n",
            " |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
            " |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
            " |  \n",
            " |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
            " |      Implement setattr(self, name, value).\n",
            " |  \n",
            " |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
            " |  \n",
            " |  __str__(self) -> 'str'\n",
            " |      Return str(self).\n",
            " |  \n",
            " |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
            " |      Returns a copy of the model.\n",
            " |      \n",
            " |      !!! warning \"Deprecated\"\n",
            " |          This method is now deprecated; use `model_copy` instead.\n",
            " |      \n",
            " |      If you need `include` or `exclude`, use:\n",
            " |      \n",
            " |      ```python {test=\"skip\" lint=\"skip\"}\n",
            " |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
            " |      data = {**data, **(update or {})}\n",
            " |      copied = self.model_validate(data)\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
            " |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
            " |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
            " |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A copy of the model with included, excluded and updated fields as specified.\n",
            " |  \n",
            " |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
            " |  \n",
            " |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
            " |  \n",
            " |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
            " |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
            " |      \n",
            " |      Returns a copy of the model.\n",
            " |      \n",
            " |      Args:\n",
            " |          update: Values to change/add in the new model. Note: the data is not validated\n",
            " |              before creating the new model. You should trust this data.\n",
            " |          deep: Set to `True` to make a deep copy of the model.\n",
            " |      \n",
            " |      Returns:\n",
            " |          New model instance.\n",
            " |  \n",
            " |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
            " |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
            " |      \n",
            " |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
            " |      \n",
            " |      Args:\n",
            " |          mode: The mode in which `to_python` should run.\n",
            " |              If mode is 'json', the output will only contain JSON serializable types.\n",
            " |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
            " |          include: A set of fields to include in the output.\n",
            " |          exclude: A set of fields to exclude from the output.\n",
            " |          context: Additional context to pass to the serializer.\n",
            " |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
            " |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
            " |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
            " |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
            " |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
            " |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
            " |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
            " |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A dictionary representation of the model.\n",
            " |  \n",
            " |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
            " |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
            " |      \n",
            " |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
            " |      \n",
            " |      Args:\n",
            " |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
            " |          include: Field(s) to include in the JSON output.\n",
            " |          exclude: Field(s) to exclude from the JSON output.\n",
            " |          context: Additional context to pass to the serializer.\n",
            " |          by_alias: Whether to serialize using field aliases.\n",
            " |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
            " |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
            " |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
            " |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
            " |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
            " |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
            " |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A JSON string representation of the model.\n",
            " |  \n",
            " |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
            " |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
            " |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from pydantic.main.BaseModel:\n",
            " |  \n",
            " |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
            " |  \n",
            " |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
            " |      Hook into generating the model's CoreSchema.\n",
            " |      \n",
            " |      Args:\n",
            " |          source: The class we are generating a schema for.\n",
            " |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
            " |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A `pydantic-core` `CoreSchema`.\n",
            " |  \n",
            " |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
            " |      Hook into generating the model's JSON schema.\n",
            " |      \n",
            " |      Args:\n",
            " |          core_schema: A `pydantic-core` CoreSchema.\n",
            " |              You can ignore this argument and call the handler with a new CoreSchema,\n",
            " |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
            " |              or just call the handler with the original schema.\n",
            " |          handler: Call into Pydantic's internal JSON schema generation.\n",
            " |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
            " |              generation fails.\n",
            " |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
            " |              `schema_generator` argument to that function to change JSON schema generation globally\n",
            " |              for a type.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A JSON schema, as a Python object.\n",
            " |  \n",
            " |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
            " |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
            " |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
            " |      be present when this is called.\n",
            " |      \n",
            " |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
            " |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
            " |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
            " |      \n",
            " |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
            " |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
            " |      \n",
            " |      Args:\n",
            " |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
            " |              by pydantic.\n",
            " |  \n",
            " |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
            " |  \n",
            " |  from_orm(obj: 'Any') -> 'Self'\n",
            " |  \n",
            " |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
            " |      Creates a new instance of the `Model` class with validated data.\n",
            " |      \n",
            " |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
            " |      Default values are respected, but no other validation is performed.\n",
            " |      \n",
            " |      !!! note\n",
            " |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
            " |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
            " |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
            " |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
            " |          an error if extra values are passed, but they will be ignored.\n",
            " |      \n",
            " |      Args:\n",
            " |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
            " |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
            " |              Otherwise, the field names from the `values` argument will be used.\n",
            " |          values: Trusted or pre-validated data dictionary.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A new instance of the `Model` class with validated data.\n",
            " |  \n",
            " |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
            " |      Generates a JSON schema for a model class.\n",
            " |      \n",
            " |      Args:\n",
            " |          by_alias: Whether to use attribute aliases or not.\n",
            " |          ref_template: The reference template.\n",
            " |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
            " |              `GenerateJsonSchema` with your desired modifications\n",
            " |          mode: The mode in which to generate the schema.\n",
            " |      \n",
            " |      Returns:\n",
            " |          The JSON schema for the given model class.\n",
            " |  \n",
            " |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
            " |      Compute the class name for parametrizations of generic classes.\n",
            " |      \n",
            " |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
            " |      \n",
            " |      Args:\n",
            " |          params: Tuple of types of the class. Given a generic class\n",
            " |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
            " |              the value `(str, int)` would be passed to `params`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          String representing the new class where `params` are passed to `cls` as type variables.\n",
            " |      \n",
            " |      Raises:\n",
            " |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
            " |  \n",
            " |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
            " |      Try to rebuild the pydantic-core schema for the model.\n",
            " |      \n",
            " |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
            " |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
            " |      \n",
            " |      Args:\n",
            " |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
            " |          raise_errors: Whether to raise errors, defaults to `True`.\n",
            " |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
            " |          _types_namespace: The types namespace, defaults to `None`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
            " |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
            " |  \n",
            " |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
            " |      Validate a pydantic model instance.\n",
            " |      \n",
            " |      Args:\n",
            " |          obj: The object to validate.\n",
            " |          strict: Whether to enforce types strictly.\n",
            " |          from_attributes: Whether to extract data from object attributes.\n",
            " |          context: Additional context to pass to the validator.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValidationError: If the object could not be validated.\n",
            " |      \n",
            " |      Returns:\n",
            " |          The validated model instance.\n",
            " |  \n",
            " |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
            " |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
            " |      \n",
            " |      Validate the given JSON data against the Pydantic model.\n",
            " |      \n",
            " |      Args:\n",
            " |          json_data: The JSON data to validate.\n",
            " |          strict: Whether to enforce types strictly.\n",
            " |          context: Extra variables to pass to the validator.\n",
            " |      \n",
            " |      Returns:\n",
            " |          The validated Pydantic model.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
            " |  \n",
            " |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
            " |      Validate the given object with string data against the Pydantic model.\n",
            " |      \n",
            " |      Args:\n",
            " |          obj: The object containing string data to validate.\n",
            " |          strict: Whether to enforce types strictly.\n",
            " |          context: Extra variables to pass to the validator.\n",
            " |      \n",
            " |      Returns:\n",
            " |          The validated Pydantic model.\n",
            " |  \n",
            " |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
            " |  \n",
            " |  parse_obj(obj: 'Any') -> 'Self'\n",
            " |  \n",
            " |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
            " |  \n",
            " |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
            " |  \n",
            " |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
            " |  \n",
            " |  update_forward_refs(**localns: 'Any') -> 'None'\n",
            " |  \n",
            " |  validate(value: 'Any') -> 'Self'\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from pydantic.main.BaseModel:\n",
            " |  \n",
            " |  __fields_set__\n",
            " |  \n",
            " |  model_computed_fields\n",
            " |      Get metadata about the computed fields defined on the model.\n",
            " |      \n",
            " |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
            " |      In V3, this property will be removed from the `BaseModel` class.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
            " |  \n",
            " |  model_extra\n",
            " |      Get extra fields set during validation.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
            " |  \n",
            " |  model_fields\n",
            " |      Get metadata about the fields defined on the model.\n",
            " |      \n",
            " |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
            " |      In V3, this property will be removed from the `BaseModel` class.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
            " |  \n",
            " |  model_fields_set\n",
            " |      Returns the set of fields that have been explicitly set on this model instance.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A set of strings representing the fields that have been set,\n",
            " |              i.e. that were not filled from defaults.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from pydantic.main.BaseModel:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables\n",
            " |  \n",
            " |  __pydantic_extra__\n",
            " |  \n",
            " |  __pydantic_fields_set__\n",
            " |  \n",
            " |  __pydantic_private__\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
            " |  \n",
            " |  __hash__ = None\n",
            " |  \n",
            " |  __pydantic_root_model__ = False\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# you can use python 'help' to see the content of the pydantic model\n",
        "from models import Claim\n",
        "\n",
        "help(Claim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "996Pws8HPc0q",
        "outputId": "afc3c8f6-6218-49a3-e18c-3a0c4db9082e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "there are 126 covered claims and 274 not covered claims.\n"
          ]
        }
      ],
      "source": [
        "claims = dataset.root\n",
        "covered_claims = [claim for claim in claims if claim.coverage]\n",
        "not_covered_claims = [claim for claim in claims if not claim.coverage]\n",
        "\n",
        "print(f\"there are {len(covered_claims)} covered claims and {len(not_covered_claims)} not covered claims.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivB5wTlNPc0q"
      },
      "source": [
        "The loaded dataset of 400 claims is notably unbalanced, with 68.5% not covered and 31.5% covered. When creating our train/test split, we'll need to monitor these proportions to maintain a representative distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rXXD8z2Pc0q"
      },
      "source": [
        "#### split train / test dataset\n",
        "\n",
        "To ensure comparable results, we'll split the dataset into training and test sets. We'll establish our baseline using only the test set. The training set will be used to finetune the model, after which we'll evaluate the finetuned model on the test set.\n",
        "\n",
        "Note: In a production environment, we would typically implement Stratified K-fold Cross Validation to maintain consistent covered/not-covered proportions across splits. For this workshop, we're keeping the approach straightforward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uCC32uiPc0r",
        "outputId": "39243f88-4e4f-4eee-e8ac-db9f140dcaed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "split 400 claims into 320 training claims and 80 testing claims\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# shuffle randomly the claims with reproducibility\n",
        "random.seed(42)\n",
        "random.shuffle(claims)\n",
        "\n",
        "# keep 80% as training set, 20% as testing set.\n",
        "split_ratio = 0.8\n",
        "train_size = int(len(claims) * split_ratio)\n",
        "\n",
        "train_claims = claims[:train_size]\n",
        "test_claims = claims[train_size:]\n",
        "\n",
        "print(f\"split {len(claims)} claims into {len(train_claims)} training claims and {len(test_claims)} testing claims\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5gpDiN5Pc0r",
        "outputId": "cb75510a-5ca0-4057-fff3-7b998cf999af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30.625% covered, 69.375% not covered\n"
          ]
        }
      ],
      "source": [
        "\n",
        "covered_train_claims = [claim for claim in train_claims if claim.coverage]\n",
        "not_covered_train_claims = [claim for claim in train_claims if not claim.coverage]\n",
        "\n",
        "print(f\"{len(covered_train_claims)*100/len(train_claims)}% covered, {len(not_covered_train_claims)*100/len(train_claims)}% not covered\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeYOjc3FPc0r",
        "outputId": "d76e36e8-e5ea-4560-ce39-4b140a78e1f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35.0% covered, 65.0% not covered\n"
          ]
        }
      ],
      "source": [
        "covered_test_claims = [claim for claim in test_claims if claim.coverage]\n",
        "not_covered_test_claims = [claim for claim in test_claims if not claim.coverage]\n",
        "\n",
        "print(f\"{len(covered_test_claims)*100/len(test_claims)}% covered, {len(not_covered_test_claims)*100/len(test_claims)}% not covered\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v7wViZBPc0r"
      },
      "source": [
        "We see a slight difference in the proportion of covered not covered between our training and testing set that could potentially impact our end results. To do it better we could make a stratified split for example using sklearn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjtvJPT1Pc0s"
      },
      "source": [
        "### Establish baseline performance Qwen2.5(3B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXhaBnVBXSOf"
      },
      "source": [
        "#### Model Definition\n",
        "\n",
        "Start by loading the model for huggingface. Thanks to unsloth we can load the model directly quantized in 4bits which enable to save a lot of bandwidth and storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673,
          "referenced_widgets": [
            "cdf5005557c1412bac6bcb200c5e7477",
            "7ef821154f89469facd135e6c753bd04",
            "978348097ca4443bbe704dc67c08a5df",
            "289fcccbc5c24c2cb2ba88224095c954",
            "536a5671b1614b428061ae8a976ec5dc",
            "a67dd91a9e4544ffb835f86202cc27c4",
            "7f8d0bd0e87e430eaf6ddae0eb88b34e",
            "eff43a3151134d83886809a0a5d6ac25",
            "e7e4d0b1e75241d1b146f71288bac94d",
            "388d59250de9466e8d4bad376ae50754",
            "36b3fdcf208045fc9065ad5b3ed83e0f",
            "909c70eb218340689e106dbe379c22fa",
            "2e68bd332805415b93954b414cd10a6d",
            "5e5ebbd7cde443f2847037248d463bb6",
            "f2ef88c4958642eea619392ef21419bc",
            "1032cfed967f463787397324c3214358",
            "4c121acc33084991acad5643e1ef0171",
            "ff95cc35a1414f9aab2ded2487af89fe",
            "f4bbe1fc94d748968cc68e5febc92a11",
            "41fccef43ad84699ac8318c782edae20",
            "ee5010e00c2246639c4fbdf5f2adff56",
            "9771087f47794ebd96fccb9eaaf289be"
          ]
        },
        "collapsed": true,
        "id": "01KFtFBcPc0s",
        "outputId": "bbb9fe0d-be41-4179-da8c-2bd29d2a4b50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.2.5: Fast Qwen2 patching. Transformers: 4.48.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit with actual GPU utilization = 49.66%\n",
            "Unsloth: Your GPU has CUDA compute capability 7.5 with VRAM = 14.74 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 1024. Num Sequences = 192.\n",
            "Unsloth: vLLM's KV Cache can use up to 4.9 GB. Also swap space = 2 GB.\n",
            "WARNING 02-13 13:48:44 config.py:2386] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 02-13 13:49:00 config.py:542] This model supports multiple tasks: {'reward', 'classify', 'generate', 'embed', 'score'}. Defaulting to 'generate'.\n",
            "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.2.mlp', 'model.layers.3.mlp', 'model.layers.30.mlp'], 'llm_int8_threshold': 6.0}\n",
            "INFO 02-13 13:49:00 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=1024, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":192}, use_cached_outputs=False, \n",
            "INFO 02-13 13:49:02 cuda.py:179] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 02-13 13:49:02 cuda.py:227] Using XFormers backend.\n",
            "INFO 02-13 13:49:03 model_runner.py:1110] Starting to load model unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W213 13:49:03.550827073 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-13 13:49:03 loader.py:1102] Loading weights with BitsAndBytes quantization.  May take a while ...\n",
            "INFO 02-13 13:49:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdf5005557c1412bac6bcb200c5e7477",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "909c70eb218340689e106dbe379c22fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-13 13:49:24 model_runner.py:1115] Loading model weights took 2.2160 GB\n",
            "INFO 02-13 13:49:24 punica_selector.py:18] Using PunicaWrapperGPU.\n",
            "INFO 02-13 13:49:28 worker.py:267] Memory profiling takes 3.42 seconds\n",
            "INFO 02-13 13:49:28 worker.py:267] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.50) = 7.32GiB\n",
            "INFO 02-13 13:49:28 worker.py:267] model weights take 2.22GiB; non_torch_memory takes 0.05GiB; PyTorch activation peak memory takes 1.05GiB; the rest of the memory reserved for KV Cache is 4.01GiB.\n",
            "INFO 02-13 13:49:28 executor_base.py:110] # CUDA blocks: 7300, # CPU blocks: 3640\n",
            "INFO 02-13 13:49:28 executor_base.py:115] Maximum concurrency for 1024 tokens per request: 114.06x\n",
            "INFO 02-13 13:49:30 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Capturing CUDA graph shapes: 100%|██████████| 27/27 [00:50<00:00,  1.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-13 13:50:20 model_runner.py:1562] Graph capturing finished in 50 secs, took 0.62 GiB\n",
            "INFO 02-13 13:50:20 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 56.41 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Unsloth 2025.2.5 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "\n",
        "max_seq_length = 1024  # Can increase for longer reasoning traces\n",
        "lora_rank = 64  # Larger rank = smarter, but slower\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"Qwen/Qwen2.5-3B-Instruct\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    load_in_4bit=True,  # False for LoRA 16bit\n",
        "    fast_inference=True,  # Enable vLLM fast inference\n",
        "    max_lora_rank=lora_rank,\n",
        "    gpu_memory_utilization=0.5,  # Reduce if out of memory\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=lora_rank,  # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "    ],  # Remove QKVO if out of memory\n",
        "    lora_alpha=lora_rank,\n",
        "    use_gradient_checkpointing=\"unsloth\",  # Enable long context finetuning\n",
        "    random_state=3407,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you are curious about what `get_peft_model` is doing:\n",
        "\n",
        "Here we just load the model and apply peft which modify each relevant modules / layer from regular pytorch modules to LoRa adapted one as follow:\n",
        "\n",
        "```python\n",
        "# Original layer\n",
        "class LinearLayer:\n",
        "    def __init__(self):\n",
        "        self.weight = Parameter(...)  # Full weight matrix\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x @ self.weight.T\n",
        "```\n",
        "\n",
        "becomes\n",
        "\n",
        "```python\n",
        "# LoRA wrapped version\n",
        "class LoRALayer:\n",
        "    def __init__(self, base_layer, rank=8):\n",
        "        self.base_layer = base_layer          # Original layer\n",
        "        self.lora_A = Parameter(...)          # Low rank matrix A (smaller)\n",
        "        self.lora_B = Parameter(...)          # Low rank matrix B (smaller)\n",
        "        self.scaling = alpha / rank           # Scaling factor\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Original computation\n",
        "        base_output = self.base_layer(x)\n",
        "        # LoRA computation\n",
        "        lora_output = (x @ self.lora_A @ self.lora_B) * self.scaling\n",
        "        # Combine both\n",
        "        return base_output + lora_output\n",
        "```\n",
        "\n",
        "Additionaly the basebone model is loaded in 4bit which translate to using the following `BitsAndBytesConfig`:\n",
        "\n",
        "```python\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit              = True,\n",
        "    bnb_4bit_use_double_quant = True,\n",
        "    bnb_4bit_quant_type       = \"nf4\",\n",
        "    bnb_4bit_compute_dtype    = dtype,\n",
        ")\n",
        "```\n",
        "\n",
        "This setup basically enable [QLoRA](https://arxiv.org/pdf/2305.14314) where the backbone model is quantised using nf4 (4 bit optimised quantisation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBIkEVFtXksU"
      },
      "source": [
        "We will then define the prompt that we will use to answer the coverage question. Feel free to experiment with different prompt here as it can significantly impact the accuracy already."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Prompt Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tRFd1hpPc0s"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"\"\"\n",
        "You are an Insurance Claim Expert.\n",
        "You are given a claim description and a list of sources extracted from the insurance policy.\n",
        "You need to determine if the claim is covered by the insurance policy based on the sources.\n",
        "\n",
        "Claim description:\n",
        "{claim.description}\n",
        "\n",
        "Sources:\n",
        "{sources}\n",
        "\n",
        "Format:\n",
        "Return only \"covered\" or \"not covered\"\n",
        "\"\"\".strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_fhqljYPc0s"
      },
      "outputs": [],
      "source": [
        "def claim_to_prompt(claim: Claim):\n",
        "    \"\"\"apply chat template and format the prompt\"\"\"\n",
        "    return tokenizer.apply_chat_template(\n",
        "        [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": PROMPT.format(\n",
        "                    claim=claim,\n",
        "                    sources=\"\\n\".join(\n",
        "                        [\n",
        "                            f\"{i + 1}. {source.paragraph}\"\n",
        "                            for i, source in enumerate(claim.sources)\n",
        "                        ]\n",
        "                    ),\n",
        "                ),\n",
        "            }\n",
        "        ],\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mRFLZ2pjPc0s",
        "outputId": "69792821-7e4a-4846-833a-2d8b2a5e20ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|im_start|>system\n",
            "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>user\n",
            "You are an Insurance Claim Expert.\n",
            "You are given a claim description and a list of sources extracted from the insurance policy.\n",
            "You need to determine if the claim is covered by the insurance policy based on the sources.\n",
            "\n",
            "Claim description:\n",
            "I discovered someone had attempted to steal my car. The driver's side door lock was damaged, and the dashboard was dismantled, with the stereo missing. Is there any provision for covering transportation and accomodation?\n",
            "\n",
            "Sources:\n",
            "1. If your car, accessories or spare parts are lost, stolen or damaged, we will: - repair the damage; - replace what is lost or damaged and is too expensive to repair; or - pay you the cost of the loss or damage.\n",
            "2. If your car is damaged, we will use one of our recommended repairers to repair it. If you choose not to use them, we may not pay more than our recommended repairer would have charged and we may choose to settle the claim by a financial payment. Following damage to your car, we may move your car to a place of safe and free storage pending settlement of any claim.\n",
            "3. Where your car is not recovered following a theft or is beyond economical repair we will pay you the market value of your car, including accessories and spare parts at the time they are lost, stolen or damaged.\n",
            "4. If we settle a claim as a total loss, we will then take ownership of your car.\n",
            "5. Accessories and spare parts of your car, which are in your private garage at the time of their loss or damage, will also be covered.\n",
            "6. You are not covered for the following:\n",
            "7. Loss or theft of your car by deception. This includes, but is not limited to: Loss or theft as a result of handing the keys of your car over to someone who claims to be a buyer or agent without taking precautions to ensure your car is returned to you. An example of an acceptable precaution is to attend the test drive with the prospective buyer. Loss or theft as a result of someone purchasing your car using a payment method which does not result in you receiving the payment for your car.\n",
            "8. Loss or damage to your car by theft or attempted theft if you or anyone else has left it unlocked or with keys or keyless entry system in your car, or on it.\n",
            "\n",
            "Format:\n",
            "Return only \"covered\" or \"not covered\"<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompts = [claim_to_prompt(claim) for claim in test_claims]\n",
        "print(prompts[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZG_vZwYZiVW"
      },
      "source": [
        "Before running inferences with our model and looking at the result it's good to check the size of the output so that we can limit the generation to only the amount of token needed.\n",
        "\n",
        "Common approach today to build tokenizer is to use algorithm similar to Byte Pair Encoding (BPE) which is \"trained\" on a dataset and determines the amount of token for a specific word / set of words. I highly recommend this video from Andrej Karpathy to dive deeper into tokenizer if interested: [video](https://www.youtube.com/watch?v=zduSFxRajkE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZFr6aqSPc0t",
        "outputId": "49a49ab8-d9a6-4fd2-9b9a-d8657e7038e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num tokens covered: 1\n",
            "num tokens not covered: 2\n"
          ]
        }
      ],
      "source": [
        "print(f\"num tokens covered: {len(tokenizer.tokenize('covered'))}\")\n",
        "print(f\"num tokens not covered: {len(tokenizer.tokenize('not covered'))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR--uYoAasYH"
      },
      "source": [
        "In here see that covered takes 1 token and 'not covered' takes 2 tokens so we will cap our generation to 2 tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv2dW-trPc0t",
        "outputId": "4c303dde-fd65-4ddf-9ab3-58ec55401ca8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts: 100%|██████████| 80/80 [00:14<00:00,  5.48it/s, est. speed input: 2009.20 toks/s, output: 10.96 toks/s]\n"
          ]
        }
      ],
      "source": [
        "from vllm import SamplingParams\n",
        "\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=2,  # set to 2 as not covered is 2 tokens\n",
        ")\n",
        "outputs = model.fast_generate(\n",
        "    prompts,\n",
        "    sampling_params=sampling_params,\n",
        "    lora_request=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-oj4B5bPc0t",
        "outputId": "a991808b-b98f-4ed0-cf81-95a444a6468f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['not covered', 'covered', 'not covered', 'covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'covered', 'covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'covered', 'not covered', 'not covered', 'not covered', 'covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'covered', 'not covered', 'not covered', 'covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'covered', 'covered', 'not covered', 'covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'covered', 'not covered', 'not covered', 'covered', 'not covered']\n"
          ]
        }
      ],
      "source": [
        "responses = []\n",
        "for response_output in outputs:\n",
        "    responses.append(response_output.outputs[0].text)\n",
        "\n",
        "print(responses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Evaluation & Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qEVWmitPc0t",
        "outputId": "6cad9a09-bffe-45c5-977b-9549321e90ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted 13 claims as covered\n",
            "Predicted 67 claims as not covered\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    f\"Predicted {len([response for response in responses if response == 'covered'])} claims as covered\"\n",
        ")\n",
        "print(\n",
        "    f\"Predicted {len([response for response in responses if response == 'not covered'])} claims as not covered\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roEXeUWWbWvC"
      },
      "source": [
        "Already we observe here that the total amount is still 80 claims as the size of our test dataset which is already a very good result considering we are using a very small model: it perfectly followed the format instruction from the prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQIPUytEPc0t",
        "outputId": "ba78ff6f-81e9-4cf3-d81c-505850fb7701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7375\n",
            "Precision: 0.7692307692307693\n",
            "Recall: 0.35714285714285715\n",
            "F1 Score: 0.4878048780487805\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred = [response.strip() == \"covered\" for response in responses]\n",
        "y_true = [claim.coverage for claim in test_claims]\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
        "print(f\"Precision: {precision_score(y_true, y_pred)}\")\n",
        "print(f\"Recall: {recall_score(y_true, y_pred)}\")\n",
        "print(f\"F1 Score: {f1_score(y_true, y_pred)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "zHFQrW0hPc0t",
        "outputId": "3d6544df-cfe2-4b3e-c97a-24ea194992d6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert responses to boolean (True for 'covered', False for 'not covered')\n",
        "y_pred = [response.strip() == \"covered\" for response in responses]\n",
        "y_true = [claim.coverage for claim in test_claims]\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=[\"Not Covered\", \"Covered\"],\n",
        "    yticklabels=[\"Not Covered\", \"Covered\"],\n",
        ")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "While we wait for the baseline model to run for everyone, here are several ways you can experiment with improving the model's performance:\n",
        "\n",
        "1. Prompt Engineering\n",
        "   - Modify the prompt structure and wording\n",
        "   - Try different instruction formats\n",
        "   - Add examples or context\n",
        "\n",
        "2. LoRA Parameter Tuning\n",
        "   - Adjust the LoRA rank (currently set to 64)\n",
        "   - Modify target modules\n",
        "   - Fine-tune the learning rate\n",
        "\n",
        "3. Output Token Optimization\n",
        "   - Experiment with alternative labels (e.g., \"YES\"/\"NO\" instead of \"covered\"/\"not covered\")\n",
        "   - Try different response formats\n",
        "   - Adjust max token length\n",
        "\n",
        "Also note that the temperature is set to 0.8 which is usually quite high for such a task but useful in the case of GRPO in the second part.\n",
        "\n",
        "Feel free to try these modifications to potentially improve the model's accuracy and performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA5ByqinPc0t"
      },
      "source": [
        "## Supervised Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpYljNhKPc0t"
      },
      "source": [
        "Fine-tuning is the process of adjusting a machine learning model's weights to achieve specific goals. In modern LLM development, teams typically follow a three-stage process:\n",
        "\n",
        "1. Pre-training\n",
        "* Model starts with random weights\n",
        "* Trained on vast amounts of internet data\n",
        "* Objective: Optimize next token prediction accuracy\n",
        "\n",
        "2. Supervised Fine-Tuning (SFT)\n",
        "* Focus on teaching the model to follow instructions\n",
        "* Creates \"Instruct\" model versions\n",
        "* Uses smaller, higher-quality datasets\n",
        "* Still employs next token prediction, but with curated instruction sets\n",
        "\n",
        "3. Reinforcement Learning\n",
        "* Further model improvement through self-learning\n",
        "* Can include Human Feedback (RLHF)\n",
        "* Model generates multiple alternatives\n",
        "* Reward function (potentially human feedback) grades responses\n",
        "* Model iteratively improves based on feedback\n",
        "\n",
        "Resource Optimization for Colab Environment\n",
        "\n",
        "While SFT typically demands significant computational resources, we can perform it in Colab using several optimization techniques:\n",
        "\n",
        "1. Model Size\n",
        "* Using a compact 3B parameter model\n",
        "* Well-suited for Colab's T4 GPU limitations\n",
        "\n",
        "2. LoRA (Low-Rank Adaptation)\n",
        "* Instead of full model fine-tuning\n",
        "* Tunes adapter layers in lower-rank space\n",
        "* More efficient than full model training\n",
        "\n",
        "3. Quantization\n",
        "* Similar to QLoRA approach\n",
        "* Backbone model remains in 4-bit precision\n",
        "* LoRA weights and gradients computed in higher precision\n",
        "* Maintains training stability while reducing memory usage\n",
        "\n",
        "All of the above is easily achievable with the library we are using in this workshop: [unsloth](https://docs.unsloth.ai/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2w-w4rpijoA"
      },
      "source": [
        "### Dataset Preparation for SFT\n",
        "\n",
        "In order to leverage hugging face trl SFTTrainer we first need to create a huggingface Dataset which will take care of creating the training batches and torch dataset based on the prompt text and the passed tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNxrt6pAPc0t"
      },
      "outputs": [],
      "source": [
        "# we create a huggingface dataset which makes it easy to load into a pytorch dataset\n",
        "# and to use with the trl library / SFTTrainer\n",
        "\n",
        "# we just need a text column for SFT (next token prediction)\n",
        "from datasets import Dataset\n",
        "\n",
        "dataset = Dataset.from_list(\n",
        "    [\n",
        "        {\n",
        "            # we just add covered / not covered to the prompt\n",
        "            # depending on the claim coverage\n",
        "            \"text\": claim_to_prompt(claim)\n",
        "            + (\"covered\" if claim.coverage else \"not covered\")\n",
        "        }\n",
        "        for claim in train_claims\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xzXSBUmPc0t",
        "outputId": "2c3c4eec-5c5d-479c-9d4c-55d06d890ea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|im_start|>system\n",
            "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>user\n",
            "You are an Insurance Claim Expert.\n",
            "You are given a claim description and a list of sources extracted from the insurance policy.\n",
            "You need to determine if the claim is covered by the insurance policy based on the sources.\n",
            "\n",
            "Claim description:\n",
            "During a routine inspection, government officials arrived at the garage and declared that several car spare parts, including the catalytic converter and the exhaust system, were not compliant with new environmental regulations. Without prior notice, they ordered the immediate confiscation of these parts, citing the need to uphold public safety standards. Is there any recourse available for unexpected regulatory compliance issues?\n",
            "\n",
            "Sources:\n",
            "1. You are not covered for the following:\n",
            "2. Confiscation or requisition or destruction by, or under the order of, any government or public or land authority.\n",
            "\n",
            "Format:\n",
            "Return only \"covered\" or \"not covered\"<|im_end|>\n",
            "<|im_start|>assistant\n",
            "not covered\n"
          ]
        }
      ],
      "source": [
        "print(dataset[0][\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARUiFj0dPc0t"
      },
      "source": [
        "### Note on DataCollator\n",
        "\n",
        "The DataCollator combine individual examples into training batches. It handles tokenization and padding of text sequences. It also ensures consistent input format for the model (usually and in this case torch tensor).\n",
        "\n",
        "For our task of claim coverage check there are 2 SFT learning approaches that could be interesting and worth trying:\n",
        "\n",
        "1. Full Sequence Learning\n",
        "* Model learns from both prompt and output tokens\n",
        "* May help model better understand the domain\n",
        "* Requires more computational resources\n",
        "* Common in API-based fine-tuning services\n",
        "\n",
        "2. Completion-Only Learning\n",
        "* Model learns only from the output tokens\n",
        "* More resource-efficient\n",
        "* Focused specifically on improving responses\n",
        "\n",
        "\n",
        "- https://github.com/huggingface/trl/issues/632 trl issue where this is explained and there is no definite conclusion on the matter.\n",
        "- https://huggingface.co/docs/trl/en/sft_trainer#train-on-completions-only we will train on completion only this time but feel free to explore with default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FmpsHmwPc0t"
      },
      "outputs": [],
      "source": [
        "# collator is responsible to format the text into batch of inputs for the model\n",
        "from trl import DataCollatorForCompletionOnlyLM\n",
        "\n",
        "response_template = \"<|im_start|>assistant\\n\"\n",
        "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run the trainer / training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "656fdb7acf614bb4b5f283140d1c73af",
            "4fe2de8d600f4203a21b7d9850dd4033",
            "46c76de7cfdf441e98a5458868c8ab33",
            "745fb46ab2cc48e58a60fa24cca256ba",
            "6e512c30d61b46fb86916990f36948d8",
            "e41444a6073c4de38e9b50e8bff3f037",
            "0164cbd1429b4eb890a53e815dba958b",
            "09abcda860834f53a49fa8219173f3fe",
            "61ec329807944556a042ce6a650c3a20",
            "1f7943ac5d124304838ce564d51fd406",
            "6a1c371160794115b92f556e45b0c4ec"
          ]
        },
        "id": "FDfpra4FPc0t",
        "outputId": "4741c7d4-3933-4ead-f5be-a9ccd1ef4915"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\n",
            "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "656fdb7acf614bb4b5f283140d1c73af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/320 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dataset_num_proc=2,\n",
        "    packing=False,  # Can make training 5x faster for short sequences.\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,  # batch size = 2\n",
        "        gradient_accumulation_steps=4,  # accumulate gradients 4 times -> equivalent to batch size 8\n",
        "        warmup_steps=5,\n",
        "        num_train_epochs=1,  # Set this for 1 full training run.\n",
        "        # max_steps=60,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps=1,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"outputs\",\n",
        "        report_to=\"none\",  # Use this for WandB etc\n",
        "    ),\n",
        "    data_collator=collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "w46OoBAxPc0u",
        "outputId": "46bba4ad-767b-42fd-a9d4-638499ac39a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 320 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 40\n",
            " \"-____-\"     Number of trainable parameters = 119,734,272\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 03:17, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.025100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.955000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.955500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.725300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.427800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.355700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.809200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.203800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.445400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.704600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.263100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.355000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.188400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.269000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.129800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.049400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.064500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.439300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.574700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.077400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.379700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.241900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.233300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.242900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.272900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.129200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.175800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.281100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.214000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.087200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.201600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.014600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.038000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.125900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.098600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.035800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.049600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.044100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.182000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.046800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Perform Inference\n",
        "\n",
        "In this section we perform inference again on the test dataset with the fine-tuned model to compare the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdNoEVipPc0y",
        "outputId": "8ff2e7b9-efd7-469b-e954-d949e0f19992"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts: 100%|██████████| 80/80 [00:13<00:00,  5.93it/s, est. speed input: 2176.94 toks/s, output: 11.87 toks/s]\n"
          ]
        }
      ],
      "source": [
        "from vllm import SamplingParams\n",
        "\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=2,  # set to 2 as not covered is 2 tokens\n",
        ")\n",
        "outputs = model.fast_generate(\n",
        "    prompts,\n",
        "    sampling_params=sampling_params,\n",
        "    lora_request=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2pySsUJPc0y",
        "outputId": "1dea8d0b-0693-4c2f-9e2a-2dee61461aad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['not covered', 'covered', 'not covered', 'covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'covered', 'covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'covered', 'not covered', 'not covered', 'not covered', 'covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'covered', 'not covered', 'not covered', 'covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'covered', 'covered', 'not covered', 'covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'not covered', 'covered', 'not covered', 'not covered', 'covered', 'not covered']\n"
          ]
        }
      ],
      "source": [
        "responses = []\n",
        "for response_output in outputs:\n",
        "    responses.append(response_output.outputs[0].text)\n",
        "\n",
        "print(responses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1gz59F8Pc0y",
        "outputId": "160b4f2e-89d6-4470-f86d-be5b12fa8ba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted 13 claims as covered\n",
            "Predicted 67 claims as not covered\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    f\"Predicted {len([response for response in responses if response == 'covered'])} claims as covered\"\n",
        ")\n",
        "print(\n",
        "    f\"Predicted {len([response for response in responses if response == 'not covered'])} claims as not covered\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSfd9LndPc0y",
        "outputId": "f41118c2-3877-4f5b-81fb-c5000dbefcbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7375\n",
            "Precision: 0.7692307692307693\n",
            "Recall: 0.35714285714285715\n",
            "F1 Score: 0.4878048780487805\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "y_pred = [response.strip() == \"covered\" for response in responses]\n",
        "y_true = [claim.coverage for claim in test_claims]\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
        "print(f\"Precision: {precision_score(y_true, y_pred)}\")\n",
        "print(f\"Recall: {recall_score(y_true, y_pred)}\")\n",
        "print(f\"F1 Score: {f1_score(y_true, y_pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv4xvJYSPc0y"
      },
      "source": [
        "We know observe better results, we can tweak more to get even better results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTBQ2nzUPc0y",
        "outputId": "8b782c0e-b83e-4e44-bbdc-74c4207afcfd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert responses to boolean (True for 'covered', False for 'not covered')\n",
        "y_pred = [response.strip() == \"covered\" for response in responses]\n",
        "y_true = [claim.coverage for claim in test_dataset]\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=[\"Not Covered\", \"Covered\"],\n",
        "    yticklabels=[\"Not Covered\", \"Covered\"],\n",
        ")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfD0TyXSnaDG"
      },
      "source": [
        "Now it's your turn to experiment! While we achieved comparable results to our baseline, there's significant room for improvement. Here are some key areas you can explore:\n",
        "\n",
        "1. Training Parameters\n",
        "   - Adjust the learning rate (currently 2e-4)\n",
        "   - Modify the number of epochs (currently 1)\n",
        "   - Try different batch sizes or gradient accumulation steps\n",
        "   - Experiment with different optimizers or scheduler types\n",
        "\n",
        "2. Model Architecture\n",
        "   - Modify the LoRA rank (currently 64)\n",
        "   - Try different target modules for LoRA adaptation\n",
        "   - Experiment with different quantization settings\n",
        "\n",
        "3. Training Strategy\n",
        "   - Switch from completion-only to full sequence learning\n",
        "   - Try different prompt templates\n",
        "   - Experiment with different response formats\n",
        "\n",
        "Take some time to modify these parameters and observe their impact on the model's performance. Remember to:\n",
        "- Keep track of your changes and their effects\n",
        "- Compare metrics (accuracy, precision, recall, F1) across different configurations\n",
        "- Consider the trade-offs between training time and performance improvements\n",
        "\n",
        "What combination of parameters will you discover that leads to better results?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0164cbd1429b4eb890a53e815dba958b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09abcda860834f53a49fa8219173f3fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1032cfed967f463787397324c3214358": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f7943ac5d124304838ce564d51fd406": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "289fcccbc5c24c2cb2ba88224095c954": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_388d59250de9466e8d4bad376ae50754",
            "placeholder": "​",
            "style": "IPY_MODEL_36b3fdcf208045fc9065ad5b3ed83e0f",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:11&lt;00:00, 11.74s/it]\n"
          }
        },
        "2e68bd332805415b93954b414cd10a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c121acc33084991acad5643e1ef0171",
            "placeholder": "​",
            "style": "IPY_MODEL_ff95cc35a1414f9aab2ded2487af89fe",
            "value": ""
          }
        },
        "36b3fdcf208045fc9065ad5b3ed83e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "388d59250de9466e8d4bad376ae50754": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41fccef43ad84699ac8318c782edae20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46c76de7cfdf441e98a5458868c8ab33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09abcda860834f53a49fa8219173f3fe",
            "max": 320,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61ec329807944556a042ce6a650c3a20",
            "value": 320
          }
        },
        "4c121acc33084991acad5643e1ef0171": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fe2de8d600f4203a21b7d9850dd4033": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e41444a6073c4de38e9b50e8bff3f037",
            "placeholder": "​",
            "style": "IPY_MODEL_0164cbd1429b4eb890a53e815dba958b",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "536a5671b1614b428061ae8a976ec5dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e5ebbd7cde443f2847037248d463bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4bbe1fc94d748968cc68e5febc92a11",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41fccef43ad84699ac8318c782edae20",
            "value": 1
          }
        },
        "61ec329807944556a042ce6a650c3a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "656fdb7acf614bb4b5f283140d1c73af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4fe2de8d600f4203a21b7d9850dd4033",
              "IPY_MODEL_46c76de7cfdf441e98a5458868c8ab33",
              "IPY_MODEL_745fb46ab2cc48e58a60fa24cca256ba"
            ],
            "layout": "IPY_MODEL_6e512c30d61b46fb86916990f36948d8"
          }
        },
        "6a1c371160794115b92f556e45b0c4ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e512c30d61b46fb86916990f36948d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "745fb46ab2cc48e58a60fa24cca256ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f7943ac5d124304838ce564d51fd406",
            "placeholder": "​",
            "style": "IPY_MODEL_6a1c371160794115b92f556e45b0c4ec",
            "value": " 320/320 [00:01&lt;00:00, 210.16 examples/s]"
          }
        },
        "7ef821154f89469facd135e6c753bd04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a67dd91a9e4544ffb835f86202cc27c4",
            "placeholder": "​",
            "style": "IPY_MODEL_7f8d0bd0e87e430eaf6ddae0eb88b34e",
            "value": ""
          }
        },
        "7f8d0bd0e87e430eaf6ddae0eb88b34e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "909c70eb218340689e106dbe379c22fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e68bd332805415b93954b414cd10a6d",
              "IPY_MODEL_5e5ebbd7cde443f2847037248d463bb6",
              "IPY_MODEL_f2ef88c4958642eea619392ef21419bc"
            ],
            "layout": "IPY_MODEL_1032cfed967f463787397324c3214358"
          }
        },
        "9771087f47794ebd96fccb9eaaf289be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "978348097ca4443bbe704dc67c08a5df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eff43a3151134d83886809a0a5d6ac25",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7e4d0b1e75241d1b146f71288bac94d",
            "value": 1
          }
        },
        "a67dd91a9e4544ffb835f86202cc27c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdf5005557c1412bac6bcb200c5e7477": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ef821154f89469facd135e6c753bd04",
              "IPY_MODEL_978348097ca4443bbe704dc67c08a5df",
              "IPY_MODEL_289fcccbc5c24c2cb2ba88224095c954"
            ],
            "layout": "IPY_MODEL_536a5671b1614b428061ae8a976ec5dc"
          }
        },
        "e41444a6073c4de38e9b50e8bff3f037": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7e4d0b1e75241d1b146f71288bac94d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee5010e00c2246639c4fbdf5f2adff56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eff43a3151134d83886809a0a5d6ac25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2ef88c4958642eea619392ef21419bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee5010e00c2246639c4fbdf5f2adff56",
            "placeholder": "​",
            "style": "IPY_MODEL_9771087f47794ebd96fccb9eaaf289be",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01&lt;00:00,  1.16s/it]\n"
          }
        },
        "f4bbe1fc94d748968cc68e5febc92a11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff95cc35a1414f9aab2ded2487af89fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
